\subsection{Metrics} \label{metrics_section}
\subsubsection{Quantitative metrics}
\textit{Coverage} metric is defined as relation of the amount tokens that were given any glossed output by FST ($N_{recognized}$) to the total amount of tokens ($N_{total}$) given to the FST:

\[Coverage = \frac{N_{recognized}}{N_{total}}\]

$N_{recognized}$ does not take into account if the given glosses are correct. It only shows the fraction of words that exist in the FST model's paradigm. 

The evaluation is done via a \texttt{Python} script \texttt{scripts/coverage/eval.py}. It reads Shughni plain text from \texttt{stdin}, which must be cleared of all punctuation. Then the script tokenizes it and feeds every token to the FST. Input texts come both in Cyrillic and Latin scripts, so the script detects writing system and calls corresponding FST variation (\texttt{sgh\_analyze\_stem\_word\_cyr.hfst} or \texttt{sgh\_analyze\_stem\_word\_lat.hfst}). The script also calculates 5 most frequent unrecognized words and most frequent unrecognized morphemes (it considers any hyphen-separated word fragments as morphemes). An example of its work is shown in the Section \ref{results_sec}.

\subsubsection*{Qualitative metrics}
There are four qualitative metrics: \textit{Precision}, \textit{Recall}, \textit{F-Score} and \textit{Accuracy(any)}. The first three metrics are evaluated conventionally:

\[Precision = \frac{TP}{TP + FP};\ 
Recall = \frac{TP}{TP + FN};\ 
FScore = \frac{2*Precision*Recall}{Precision + Recall}\]

Where \texttt{TP} = `\textit{True positive}', \texttt{FP} = `\textit{False positive}' and \texttt{FN} = `\textit{False negative}'. The principle of these values' evaluation by \texttt{scripts/metrics/eval.py} is the following: 
\begin{enumerate}
    \item The script loads the Gold Standard's pairs of wordforms and glossed strings
    \item For each unique wordform$_i$:
    \begin{enumerate}
        \item all possible Gold Standard's glossed strings are gathered for wordform$_i$ ($=G_i$)
        \item wordform$_i$ is fed into a FST analyzer and all possible predicted glossed strings are gathered ($=P_i$)
        \item the following is calculated: \\
        $TP_i = |G_i \cap P_i|$ (amount of elements in intersection)\\
        $FN_i = |G_i \setminus P_i|$ (amount of elements in $G_i$ that are not in $P_i$)\\
        $FP_i = |P_i \setminus G_i|$ (amount of elements in $P_i$ that are not in $G_i$)
    \end{enumerate}
    \item Total $TP$, $FN$ and $FP$ are calculated from the sum of respective $TP_i$, $FN_i$ and $FP_i$
\end{enumerate}

In other words, $TP$, $FP$ and $FN$ can be thought of as following:
\begin{itemize}
    \item $TP$: a glossed string is present both in gold standard and FST output.
    \item $FP$: a glossed string is present in FST output but not in gold standard.
    \item $FN$: a glossed string is present in gold standard but not in FST output.
\end{itemize}

\begin{table}[!htbp]
    \begin{center}
        \begin{tabular}{|l||c|c|}
            \hline
            \diagbox{FST output}{Gold standard} & Present & Not present \\
            \hline
            \hline
            Present & TP & FP \\
            \hline
            Not present & FN & - \\
            \hline
        \end{tabular}
        \caption{textit{TP}, \textit{FP} and \textit{FN} interpretations.}
        \label{Tab:10_1}
    \end{center}
\end{table}
